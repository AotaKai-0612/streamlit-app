import streamlit as st
import pandas as pd
from googleapiclient.discovery import build
from openai import OpenAI
from dotenv import load_dotenv
import os
import time
import json
import re
import concurrent.futures

# 1. ç’°å¢ƒè¨­å®š ---------------------------------------------------------
load_dotenv()
YOUTUBE_API_KEY = os.getenv("YOUTUBE_API_KEY")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

if not YOUTUBE_API_KEY or not OPENAI_API_KEY:
    st.error("âŒ APIã‚­ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚.env ã« YOUTUBE_API_KEY ã¨ OPENAI_API_KEY ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
    st.stop()

youtube = build("youtube", "v3", developerKey=YOUTUBE_API_KEY)
client = OpenAI(api_key=OPENAI_API_KEY)

st.set_page_config(page_title="YouTubeã‚³ãƒ¡ãƒ³ãƒˆåˆ†æã‚·ã‚¹ãƒ†ãƒ ", layout="wide")
st.title("ğŸ¥ YouTubeã‚³ãƒ¡ãƒ³ãƒˆåˆ†æã‚·ã‚¹ãƒ†ãƒ ")

# 2. å®šæ•°ãƒ»ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° ----------------------------------
FEATURES = [
    {"key": "æ”»æ’ƒæ€§", "min": 0, "max": 3, "desc": "ä»–è€…ã¸ã®ç›´æ¥çš„ãªæ•µæ„ãƒ»ä¾®è¾±ãƒ»è„…è¿«ã®åº¦åˆã„ã€‚0=ãªã—, 3=é«˜"},
    {"key": "æŒ‘ç™ºæ€§", "min": 0, "max": 3, "desc": "çš®è‚‰ãƒ»ç…½ã‚Šç­‰ã§åå¿œã‚’å¼•ãå‡ºã™åº¦åˆã„ã€‚0=ãªã—, 3=é«˜"},
    {"key": "æœ‰ç”¨æ€§", "min": 0, "max": 3, "desc": "å‹•ç”»ã‚„è¦–è´è€…ã«ã¨ã£ã¦æœ‰ç›Šã‹ï¼ˆ0=ãªã—, 3=é«˜ï¼‰"},
    {"key": "æ„Ÿæƒ…æ¥µæ€§", "min": -2, "max": 2, "desc": "æ„Ÿæƒ…ã®ãƒˆãƒ¼ãƒ³ã€‚-2=å¼·ã„ãƒã‚¬ãƒ†ã‚£ãƒ–, 0=ä¸­ç«‹, +2=å¼·ã„ãƒã‚¸ãƒ†ã‚£ãƒ–"},
    {"key": "è‡ªå·±é¡•ç¤ºæ€§", "min": 0, "max": 3, "desc": "è‡ªåˆ†ã®çŸ¥è­˜ã‚„çµŒæ­´ã§å„ªä½æ€§ã‚’ç¤ºã™åº¦åˆã„"},
    {"key": "æ–‡è„ˆä¾å­˜æ€§", "min": 0, "max": 3, "desc": "å†…è¼ªãƒã‚¿ã‚„å°‚é–€ç”¨èªã®é »åº¦ã€‚0=ã‚ã‹ã‚Šã‚„ã™ã„, 3=é«˜åº¦ã«ä¾å­˜"}
]

def extract_number_from_text(s):
    if s is None:
        return None
    if isinstance(s, (int, float)):
        return s
    m = re.search(r"-?\d+(\.\d+)?", str(s))
    if m:
        try:
            if '.' in m.group(0):
                return float(m.group(0))
            else:
                return int(m.group(0))
        except:
            return None
    return None

def normalize_analysis_to_row(analysis):
    row = {}
    reasons = []
    model_overall = None
    if isinstance(analysis, dict):
        model_overall = analysis.get("ç·åˆã‚³ãƒ¡ãƒ³ãƒˆ") or analysis.get("ç·åˆè©•ä¾¡") or analysis.get("ç·åˆ") or analysis.get("ç·åˆã‚³ãƒ¡ãƒ³ãƒˆï¼ˆè¦ç´„ï¼‰")
    for f in FEATURES:
        k = f["key"]
        val = None
        score = None
        reason = None
        if isinstance(analysis, dict):
            val = analysis.get(k)
        if isinstance(val, dict):
            score = val.get("score") if "score" in val else extract_number_from_text(val.get("value") or val.get("level") or None)
            reason = val.get("reason") or val.get("explanation") or None
        elif isinstance(val, (int, float)):
            score = val
        elif isinstance(val, str):
            score = extract_number_from_text(val)
            reason = re.sub(r"-?\d+(\.\d+)?", "", val).strip(" :,-ã€‚ï¼")
            if reason == "":
                reason = None
        if score is None and isinstance(analysis, dict):
            alt_key = f"{k}_score"
            if alt_key in analysis:
                score = extract_number_from_text(analysis.get(alt_key))
            alt2 = k.lower() + "_score"
            if score is None and alt2 in analysis:
                score = extract_number_from_text(analysis.get(alt2))
        row[f"{k}_score"] = score
        if reason:
            reasons.append(f"{k}ï¼š{reason}")
    if model_overall and isinstance(model_overall, str) and model_overall.strip():
        overall = model_overall
    else:
        if reasons:
            overall = "ãƒ¢ãƒ‡ãƒ«ç†ç”±ã«åŸºã¥ãç·åˆã‚³ãƒ¡ãƒ³ãƒˆ â€” " + "ï¼›".join(reasons[:6])
        else:
            if isinstance(analysis, dict) and "raw_output" in analysis:
                overall = f"ãƒ¢ãƒ‡ãƒ«å‡ºåŠ›ï¼ˆéJSONï¼‰: {str(analysis['raw_output'])[:300]}"
            elif isinstance(analysis, dict) and any(k not in [f"{ft['key']}_score" for ft in FEATURES] for k in analysis.keys()):
                overall = "ãƒ¢ãƒ‡ãƒ«å‡ºåŠ›: " + ", ".join(list(analysis.keys())[:5])
            else:
                overall = "è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸç·åˆã‚³ãƒ¡ãƒ³ãƒˆï¼šè©³ç´°ãªç†ç”±ãŒãƒ¢ãƒ‡ãƒ«ã‹ã‚‰å¾—ã‚‰ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚"
    row["ç·åˆã‚³ãƒ¡ãƒ³ãƒˆ"] = overall
    return row

# 3. APIé–¢é€£é–¢æ•° ---------------------------------------

# ã€æ”¹å–„ç‚¹ã€‘ã€Œã‚‚ã£ã¨è¦‹ã‚‹ã€ãƒœã‚¿ãƒ³ã®ãŸã‚ã«ãƒšãƒ¼ã‚¸ãƒˆãƒ¼ã‚¯ãƒ³å¯¾å¿œã‚’è¿½åŠ 
def search_videos(query, max_results=6, page_token=None):
    try:
        req = youtube.search().list(
            part="snippet", q=query, type="video",
            videoEmbeddable="true", maxResults=max_results, order="relevance",
            pageToken=page_token 
        )
        res = req.execute()
    except Exception as e:
        st.error(f"æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
        return [], None
    
    results = []
    for item in res.get("items", []):
        vid = item.get("id", {}).get("videoId")
        if not vid: continue
        snip = item.get("snippet", {})
        results.append({
            "title": snip.get("title"),
            "video_id": vid,
            "thumbnail": snip.get("thumbnails", {}).get("medium", {}).get("url")
        })
    
    next_token = res.get("nextPageToken")
    return results, next_token

def get_comments(video_id, max_comments=100):
    comments = []
    try:
        request = youtube.commentThreads().list(
            part="snippet",
            videoId=video_id,
            maxResults=100,
            textFormat="plainText",
            order="relevance"
        )
        while request and len(comments) < max_comments:
            response = request.execute()
            for item in response.get("items", []):
                try:
                    c = item["snippet"]["topLevelComment"]["snippet"]["textDisplay"]
                    comments.append(c)
                except KeyError:
                    continue
            if len(comments) < max_comments:
                request = youtube.commentThreads().list_next(request, response)
            else:
                break
    except Exception as e:
        st.warning(f"ã‚³ãƒ¡ãƒ³ãƒˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return []
    return comments[:max_comments]

# ã€é‡è¦ä¿®æ­£ã€‘ã“ã“ãŒä»Šå›ã®ä¿®æ­£ãƒã‚¤ãƒ³ãƒˆã§ã™ï¼
def analyze_comment(comment_text):
    prompt = f"""
    ã‚ãªãŸã¯YouTubeã‚³ãƒ¡ãƒ³ãƒˆã‚’åˆ†æã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚
    ä»¥ä¸‹ã®ãƒ«ãƒ¼ãƒ«ã«ã€å³å¯†ã«ã€‘å¾“ã£ã¦ã€æŒ‡å®šã•ã‚ŒãŸYouTubeã‚³ãƒ¡ãƒ³ãƒˆã‚’6ã¤ã®ç‰¹å¾´é‡ã§åˆ†æã—ã€JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
    ã‚³ãƒ¡ãƒ³ãƒˆã®è¡¨é¢ä¸Šã®æ„å‘³ã ã‘ã§ãªãã€æ–‡è„ˆçš„ãƒ»åèªçš„ãªæ„å‘³ï¼ˆä¾‹ï¼šã€Œè‰¯ã„å‹•ç”»ãªã®ã§ã„ã„ã­ã‚’äºŒå›æŠ¼ã—ã¾ã—ãŸï¼ã€ãªã©ã®çš®è‚‰è¡¨ç¾ï¼‰ã‚‚è€ƒæ…®ã—ã¦è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚

    # åˆ†æãƒ«ãƒ¼ãƒ«

    ##  1. æ”»æ’ƒæ€§ (Aggressiveness)
    - **ä½•ã‚’æ¸¬ã‚‹ã‹**: ã‚³ãƒ¡ãƒ³ãƒˆã«å«ã¾ã‚Œã‚‹ã€ä»–è€…ã¸ã®ç›´æ¥çš„ãªæ•µæ„ã€ä¾®è¾±ã€è„…è¿«ã®åº¦åˆã„ã€‚
    - **ãƒ¬ãƒ™ãƒ«0: ãªã—**: æ•¬æ„ãŒæ‰•ã‚ã‚Œã¦ã„ã‚‹ã€ã‚‚ã—ãã¯ä¸­ç«‹çš„ã€‚ç„¡ç¤¼ãªè¨€è‘‰é£ã„ãŒä¸€åˆ‡å«ã¾ã‚Œãªã„ã€‚ï¼ˆä¾‹: ã€Œã„ã¤ã‚‚å‹•ç”»ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚ã€ï¼‰
    - **ãƒ¬ãƒ™ãƒ«1: ä½**: ç›¸æ‰‹ã‚’å°é¦¬é¹¿ã«ã™ã‚‹ã€è¦‹ä¸‹ã™ã‚ˆã†ãªè¡¨ç¾ã€‚ç›´æ¥çš„ãªæš´è¨€ã§ã¯ãªã„ãŒã€ç„¡ç¤¼ã§ç›¸æ‰‹ã‚’ä¸å¿«ã«ã•ã›ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚ï¼ˆä¾‹: ã€Œãã‚“ãªã“ã¨ã‚‚çŸ¥ã‚‰ãªã„ã®ï¼Ÿã€ï¼‰
    - **ãƒ¬ãƒ™ãƒ«2: ä¸­**: ç‰¹å®šã®å€‹äººã‚„æ„è¦‹ã«å¯¾ã™ã‚‹ç›´æ¥çš„ãªæ‚ªå£ã€äººæ ¼å¦å®šã€å˜²ç¬‘ã€‚ã€Œãƒã‚«ã€ã€Œã‚­ãƒ¢ã„ã€ãªã©ã€æ˜ç¢ºãªæ•µæ„ã‚„ä¾®è¾±ãŒå«ã¾ã‚Œã‚‹ã€‚ï¼ˆä¾‹: ã€Œã“ã„ã¤ãƒã‚¸ã§é ­æ‚ªã„ãªã€‚ã€ï¼‰
    - **ãƒ¬ãƒ™ãƒ«3: é«˜**: è„…è¿«ã€ãƒ˜ã‚¤ãƒˆã‚¹ãƒ”ãƒ¼ãƒã€è‡ªæ®ºã®æ•™å”†ãªã©ã€å¿ƒèº«ã®å®‰å…¨ã‚’è„…ã‹ã™è¡¨ç¾ã€‚ï¼ˆä¾‹: ã€Œã“ã†ã„ã†å¥´ã¯ç¤¾ä¼šã‹ã‚‰æ¶ˆãˆã‚ã€‚ã€ï¼‰

    ##  2. æŒ‘ç™ºæ€§ (Provocation)
    - **ä½•ã‚’æ¸¬ã‚‹ã‹**: çš®è‚‰ã€å«Œå‘³ã€æ±ºã‚ã¤ã‘ã€ç…½ã‚Šãªã©ã€ç›¸æ‰‹ã®æ„Ÿæƒ…ã‚’é€†æ’«ã§ã—ã¦åå¿œã‚’å¼•ãå‡ºãã†ã¨ã™ã‚‹æ„å›³ã®åº¦åˆã„ã€‚
    - **ãƒ¬ãƒ™ãƒ«0: ãªã—**: èª å®Ÿã§ã‚¹ãƒˆãƒ¬ãƒ¼ãƒˆãªè¡¨ç¾ã€‚è£ã®æ„å›³ã‚’æ„Ÿã˜ã•ã›ãªã„ã€‚ï¼ˆä¾‹: ã€Œç·¨é›†ãŠç–²ã‚Œæ§˜ã§ã™ï¼ã€ï¼‰
    - **ãƒ¬ãƒ™ãƒ«1: ä½**: è»½åº¦ã®çš®è‚‰ã‚„å«Œå‘³ã€‚åˆ†ã‹ã‚‹äººã«ã¯åˆ†ã‹ã‚‹ãŒã€æ–‡å­—é€šã‚Šå—ã‘å–ã‚‹ã“ã¨ã‚‚ã§ãã‚‹ã‚ˆã†ãªã€æ›–æ˜§ã•ã‚’å«ã‚€è¡¨ç¾ã€‚ï¼ˆä¾‹: ã€Œè¬ç½ªå‹•ç”»ã§ãŒã£ã½ã‚Šç¨¼ã’ã¦ã‚ˆã‹ã£ãŸã­ã€‚ã€ï¼‰
    - **ãƒ¬ãƒ™ãƒ«2: ä¸­**: æ˜ç¢ºãªã€Œä¸Šã‹ã‚‰ç›®ç·šã€ã€ãƒ¬ãƒƒãƒ†ãƒ«è²¼ã‚Šã€æ„å›³çš„ãªæšã’è¶³å–ã‚Šã€‚ã€Œä¿¡è€…ã€ã€Œã‚¢ãƒ³ãƒã€ãªã©ã®è¨€è‘‰ã‚’ä½¿ã„ã€å¯¾ç«‹ã‚’ç…½ã‚‹ã€‚ï¼ˆä¾‹: ã€Œä¿¡è€…ã•ã‚“ãŸã¡ãŒå¿…æ­»ã«æ“è­·ã—ã¦ã¦è‰ã€‚ã€ï¼‰
    - **ãƒ¬ãƒ™ãƒ«3: é«˜**: è­°è«–ã‚’ç ´å£Šã—ã€å ´ã‚’è’ã‚‰ã™ã“ã¨ã‚’ç›®çš„ã¨ã—ãŸæ‚ªè³ªãªç…½ã‚Šã€‚ï¼ˆä¾‹: ã€Œã¯ã„è«–ç ´ã€‚åè«–ã§ããªã„ãªã‚‰ä¿ºã®å‹ã¡ã­ã€‚ã€ï¼‰

    ##  3. æœ‰ç”¨æ€§ (Usefulness)
    - **ä½•ã‚’æ¸¬ã‚‹ã‹**: å‹•ç”»ã®å†…å®¹ã‚„ä»–ã®è¦–è´è€…ã«å¯¾ã—ã¦ã€æœ‰ç›Šãªä¾¡å€¤ã‚’æä¾›ã—ã¦ã„ã‚‹åº¦åˆã„ã€‚
    - **ãƒ¬ãƒ™ãƒ«0: ãªã—**: ã€Œè‰ã€ã€Œå¥½ãã€ãªã©ã€ä¸­èº«ã®ãªã„ç›¸æ§Œã‚„å˜ãªã‚‹æ„Ÿæƒ…è¡¨ç¾ã€‚ï¼ˆä¾‹: ã€Œè‰ã€ï¼‰
    - **ãƒ¬ãƒ™ãƒ«1: ä½**: å…·ä½“çš„ãªæ ¹æ‹ ã®ãªã„ã€å€‹äººã®æ„Ÿæƒ³ã‚„æ¼ ç„¶ã¨ã—ãŸæ„è¦‹ã€‚ï¼ˆä¾‹: ã€Œä»Šå›ã®å‹•ç”»é¢ç™½ããªã‹ã£ãŸãªã€‚ã€ï¼‰
    - **ãƒ¬ãƒ™ãƒ«2: ä¸­**: å…·ä½“çš„ãªæŒ‡æ‘˜ã€æ”¹å–„ææ¡ˆã€æ ¹æ‹ ã®ã‚ã‚‹æ„è¦‹ã€ä½“é¨“è«‡ãªã©ã€å‚è€ƒã«ãªã‚‹æƒ…å ±ã‚’å«ã‚€ã€‚ï¼ˆä¾‹: ã€ŒBGMãŒå¤§ãã™ãã¦ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãŒèãå–ã‚Šã¥ã‚‰ã‹ã£ãŸã§ã™ã€‚ã€ï¼‰
    - **ãƒ¬ãƒ™ãƒ«3: é«˜**: å°‚é–€çš„ãªçŸ¥è­˜ã«åŸºã¥ãæ·±ã„åˆ†æã€ãƒ‡ãƒ¼ã‚¿ã‚„å‡ºå…¸ã‚’ç”¨ã„ãŸå®¢è¦³çš„ãªè¨‚æ­£ãªã©ã€æ¥µã‚ã¦ä¾¡å€¤ã®é«˜ã„æƒ…å ±ã‚’å«ã‚€ã€‚ï¼ˆä¾‹: ã€Œã“ã®ä»¶ã€ã€‡ã€‡ã¨ã„ã†æ³•å¾‹ã®ç¬¬â–³æ¡ã«æŠµè§¦ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ã€ï¼‰

    ##  4. æ„Ÿæƒ…æ¥µæ€§ (Sentiment Polarity)
    - **ä½•ã‚’æ¸¬ã‚‹ã‹**: ã‚³ãƒ¡ãƒ³ãƒˆå…¨ä½“ã®æ„Ÿæƒ…çš„ãªãƒˆãƒ¼ãƒ³ã€‚
    - **ãƒ¬ãƒ™ãƒ«-2: å¼·ã„ãƒã‚¬ãƒ†ã‚£ãƒ–**: å¼·ã„æ€’ã‚Šã€æ†ã—ã¿ã€è»½è”‘ãªã©ã€‚ï¼ˆä¾‹: ã€Œå²ä¸Šæœ€æ‚ªã®å‹•ç”»ã€‚æ™‚é–“ã®ç„¡é§„ã ã£ãŸã€‚ã€ï¼‰
    - **ãƒ¬ãƒ™ãƒ«-1: ãƒã‚¬ãƒ†ã‚£ãƒ–**: æ‰¹åˆ¤ã€å¤±æœ›ã€ä¸æº€ãªã©ã€‚ï¼ˆä¾‹: ã€ŒæœŸå¾…ã—ã¦ãŸå†…å®¹ã¨é•ã£ã¦å°‘ã—æ®‹å¿µã§ã—ãŸã€‚ã€ï¼‰
    - **ãƒ¬ãƒ™ãƒ«0: ä¸­ç«‹**: äº‹å®Ÿã®è¨˜è¿°ã€è³ªå•ãªã©ã€æ„Ÿæƒ…çš„ãªè‰²åˆã„ãŒã»ã¨ã‚“ã©ãªã„ã€‚ï¼ˆä¾‹: ã€Œã“ã®å•†å“ã¯ã©ã“ã§è²·ãˆã¾ã™ã‹ï¼Ÿã€ï¼‰
    - **ãƒ¬ãƒ™ãƒ«+1: ãƒã‚¸ãƒ†ã‚£ãƒ–**: å¥½æ„ã€æ„Ÿè¬ã€è³è³›ãªã©ã€‚ï¼ˆä¾‹: ã€Œé¢ç™½ã‹ã£ãŸã§ã™ï¼æ¬¡å›ã®å‹•ç”»ã‚‚æ¥½ã—ã¿ã«ã—ã¦ã„ã¾ã™ï¼ã€ï¼‰
    - **ãƒ¬ãƒ™ãƒ«+2: å¼·ã„ãƒã‚¸ãƒ†ã‚£ãƒ–**: æ„Ÿå‹•ã€ç†±ç‹‚ã€æ·±ã„æ„Ÿè¬ãªã©ã€‚ï¼ˆä¾‹: ã€Œæ„Ÿå‹•ã§æ¶™ãŒå‡ºã¾ã—ãŸã€‚ä¸€ç”Ÿã¤ã„ã¦ã„ãã¾ã™ï¼ã€ï¼‰

    ##  5. è‡ªå·±é¡•ç¤ºæ€§ (Self-display / Superiority)
    - **ä½•ã‚’æ¸¬ã‚‹ã‹**: è‡ªåˆ†ã®çŸ¥è­˜ã‚„çµŒé¨“ãªã©ã‚’ã‚¢ãƒ”ãƒ¼ãƒ«ã—ã€å„ªä½ã«ç«‹ã¨ã†ã¨ã™ã‚‹æ„å›³ã®åº¦åˆã„ã€‚
    - **ãƒ¬ãƒ™ãƒ«0: ãªã—**: è‡ªåˆ†ã‚’ã‚¢ãƒ”ãƒ¼ãƒ«ã™ã‚‹æ„å›³ãŒè¦‹ã‚‰ã‚Œãªã„ã€‚ï¼ˆä¾‹: ã€Œã“ã®è€ƒãˆæ–¹ã¯é¢ç™½ã„ã§ã™ã­ã€‚ã€ï¼‰
    - **ãƒ¬ãƒ™ãƒ«1: ä½**: è©±é¡Œã«é–¢é€£ã—ãŸè‡ªåˆ†ã®ä½“é¨“è«‡ã‚„çŸ¥è­˜ã‚’ã€è£œè¶³æƒ…å ±ã¨ã—ã¦å…±æœ‰ã—ã¦ã„ã‚‹ã€‚ï¼ˆä¾‹: ã€Œç§ãŒæ˜”ã€‡ã€‡ã«è¡Œã£ãŸæ™‚ã‚‚åŒã˜ã‚ˆã†ãªæ„Ÿã˜ã§ã—ãŸã‚ˆã€‚ã€ï¼‰
    - **ãƒ¬ãƒ™ãƒ«2: ä¸­**: æŠ•ç¨¿è€…ã®èª¬æ˜ã«å¯¾ã—ã€è¨‚æ­£ã‚„è£œè¶³ã¨ã„ã†å½¢ã§ã€ã‚ˆã‚Šå°‚é–€çš„ãªçŸ¥è­˜ã‚„è‡ªèº«ã®æˆåŠŸä½“é¨“ã‚’æŠ«éœ²ã—ã€æš—ã«å„ªä½æ€§ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚ï¼ˆä¾‹: ã€Œã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æŠ•è³‡ã¯åˆå¿ƒè€…å‘ã‘ã§ã™ã‚ˆã­ã€‚åƒ•ã¯ãã‚Œã§è³‡ç”£8æ¡ã„ãã¾ã—ãŸã€‚ã€ï¼‰
    - **ãƒ¬ãƒ™ãƒ«3: é«˜**: çµŒæ­´ã€å¹´åãªã©ã‚’æç¤ºã—ã€ä»–è€…ã‚’ç›´æ¥çš„ãƒ»é–“æ¥çš„ã«è¦‹ä¸‹ã™ã€‚ï¼ˆä¾‹: ã€Œå¹´åã€‡ã€‡ä¸‡ä»¥ä¸‹ã®äººã¯ã“ã®å‹•ç”»è¦‹ã¦ã‚‚æ„å‘³ãªã„ã‚ˆã€‚ã€ï¼‰

    ##  6. æ–‡è„ˆä¾å­˜æ€§ (Context-dependency / In-groupness)
    - **ä½•ã‚’æ¸¬ã‚‹ã‹**: å†…è¼ªã«ã—ã‹çœŸæ„ãŒä¼ã‚ã‚‰ãªã„ã€å°‚é–€ç”¨èªã‚„å†…è¼ªãƒã‚¿ãŒã©ã®ç¨‹åº¦å«ã¾ã‚Œã¦ã„ã‚‹ã‹ã€‚
    - **ãƒ¬ãƒ™ãƒ«0: ãªã—**: èª°ãŒèª­ã‚“ã§ã‚‚ç†è§£ã§ãã‚‹ã€ä¸€èˆ¬çš„ã§å¹³æ˜“ãªè¨€è‘‰é£ã„ã€‚ï¼ˆä¾‹: ã€Œä»Šæ—¥ã®å¤•é£¯ã¯ã‚«ãƒ¬ãƒ¼ã«ã—ã‚ˆã†ã¨æ€ã„ã¾ã™ã€‚ã€ï¼‰
    - **ãƒ¬ãƒ™ãƒ«1: ä½**: éå»ã®å‹•ç”»ã§ã®å‡ºæ¥äº‹ã«è¨€åŠã—ã¦ã„ã‚‹ãŒã€æ–‡è„ˆã‚’çŸ¥ã‚‰ãªãã¦ã‚‚å¤§æ„ã¯æ¨æ¸¬ã§ãã‚‹ã€‚ï¼ˆä¾‹: ã€Œå‰å›ã®å‹•ç”»ã§è¨€ã£ã¦ãŸã€‡ã€‡ã®ä»¶ã€è§£æ±ºã—ã¦ã‚ˆã‹ã£ãŸï¼ã€ï¼‰
    - **ãƒ¬ãƒ™ãƒ«2: ä¸­**: ãƒ•ã‚¡ãƒ³ã®é–“ã ã‘ã§é€šã˜ã‚‹æ„›ç§°ã€ãƒŸãƒ¼ãƒ ã€æ±ºã¾ã‚Šæ–‡å¥ãªã©ãŒä½¿ã‚ã‚Œã¦ãŠã‚Šã€åˆè¦‹ã«ã¯æ„å‘³ãŒåˆ†ã‹ã‚Šã«ãã„ã€‚ï¼ˆä¾‹: ã€Œã•ã™ãŒã€‡ã€‡ã•ã‚“ï¼ˆãƒ•ã‚¡ãƒ³ã®æ„›ç§°ï¼‰ã€ä»Šæ—¥ã‚‚å¹³å¸¸é‹è»¢ã§å®‰å¿ƒã—ãŸã€‚ã€ï¼‰
    - **ãƒ¬ãƒ™ãƒ«3: é«˜**: èƒŒæ™¯çŸ¥è­˜ãŒãªã‘ã‚Œã°ã€ã‚³ãƒ¡ãƒ³ãƒˆã®æ„å‘³ã‚’å…¨ãç†è§£ã§ããªã„ã€‚ï¼ˆä¾‹: ã€Œä»Šæ—¥ã®å‹•ç”»ã¯å®Œå…¨ã«ã€ä¾‹ã®ã‚ã®ä»¶ã€ã ãªâ€¦ã€ï¼‰


    æœ€å¾Œã«ç·åˆã‚³ãƒ¡ãƒ³ãƒˆã¨ã—ã¦ã€è©•ä¾¡ç†ç”±ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚

    # å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆJSONï¼‰
    å¿…ãš **æœ‰åŠ¹ãªJSONå½¢å¼** ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
    {{
      "æ”»æ’ƒæ€§": {{"score": 0-3 }},
      "æŒ‘ç™ºæ€§": {{"score": 0-3 }},
      "æœ‰ç”¨æ€§": {{"score": 0-3 }},
      "æ„Ÿæƒ…æ¥µæ€§": {{"score": -2ã€œ+2 }},
      "è‡ªå·±é¡•ç¤ºæ€§": {{"score": 0-3 }},
      "æ–‡è„ˆä¾å­˜æ€§": {{"score": 0-3 }},
      "ç·åˆã‚³ãƒ¡ãƒ³ãƒˆ": "..."
    }}

    # åˆ†æå¯¾è±¡ã‚³ãƒ¡ãƒ³ãƒˆ
    {comment_text}
    """
    try:
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role":"user", "content": prompt}],
            temperature=0.2
        )
        raw = resp.choices[0].message.content.strip()
        
        # ----------------------------------------------------
        # ã€ä¿®æ­£ã€‘GPTãŒ ```json ... ``` ã¨ã„ã†å½¢å¼ã§è¿”ã—ã¦ããŸå ´åˆã«å‚™ãˆã¦
        # ä½™è¨ˆãªæ–‡å­—ã‚’å‰Šé™¤ã™ã‚‹å‡¦ç†ã‚’è¿½åŠ ã—ã¾ã—ãŸã€‚ã“ã‚Œã§ç›´ã‚Šã¾ã™ã€‚
        # ----------------------------------------------------
        raw = re.sub(r"```json", "", raw)
        raw = re.sub(r"```", "", raw)
        raw = raw.strip()

        try:
            return json.loads(raw)
        except json.JSONDecodeError:
            return {"raw_output": raw}
    except Exception as e:
        return {"error": str(e)}

# 4. ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š ---------------------------------------
st.sidebar.header("ğŸ”§ ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆé–¾å€¤ãƒ¬ãƒ³ã‚¸ï¼‰è¨­å®š")

preset = st.sidebar.radio("ãƒ—ãƒªã‚»ãƒƒãƒˆã‚’é¸ã¶", ["ãƒ•ã‚£ãƒ«ã‚¿ãªã—", "å¹³å’Œãƒ¢ãƒ¼ãƒ‰", "è­°è«–ãƒ¢ãƒ¼ãƒ‰", "ã‚«ã‚¹ã‚¿ãƒ "], index=0)

if preset == "ãƒ•ã‚£ãƒ«ã‚¿ãªã—":
    preset_ranges = {
        "æ”»æ’ƒæ€§": (0,3), "æŒ‘ç™ºæ€§": (0,3), "æœ‰ç”¨æ€§": (0,3), "æ„Ÿæƒ…æ¥µæ€§": (-2,2),
        "è‡ªå·±é¡•ç¤ºæ€§": (0,3), "æ–‡è„ˆä¾å­˜æ€§": (0,3)
    }
elif preset == "å¹³å’Œãƒ¢ãƒ¼ãƒ‰":
    preset_ranges = {
        "æ”»æ’ƒæ€§": (0,1), "æŒ‘ç™ºæ€§": (0,1), "æœ‰ç”¨æ€§": (0,3), "æ„Ÿæƒ…æ¥µæ€§": (0,2),
        "è‡ªå·±é¡•ç¤ºæ€§": (0,3), "æ–‡è„ˆä¾å­˜æ€§": (0,3)
    }
elif preset == "è­°è«–ãƒ¢ãƒ¼ãƒ‰":
    preset_ranges = {
        "æ”»æ’ƒæ€§": (0,2), "æŒ‘ç™ºæ€§": (0,2), "æœ‰ç”¨æ€§": (1,3), "æ„Ÿæƒ…æ¥µæ€§": (-2,2),
        "è‡ªå·±é¡•ç¤ºæ€§": (0,3), "æ–‡è„ˆä¾å­˜æ€§": (0,3)
    }
else:
    preset_ranges = {f["key"]:(f["min"], f["max"]) for f in FEATURES}

threshold_ranges = {}
with st.sidebar.expander("å„ç‰¹å¾´é‡ã®èª¬æ˜ã¨é–¾å€¤è¨­å®šï¼ˆç¯„å›²ï¼‰", expanded=True):
    for f in FEATURES:
        key = f["key"]
        st.markdown(f"**{key}** â€” {f['desc']}")
        min_v, max_v = f["min"], f["max"]
        init_min, init_max = preset_ranges.get(key, (min_v, max_v))
        rng = st.slider(f"{key} ã®è¨±å®¹ãƒ¬ãƒ³ã‚¸", min_v, max_v, (init_min, init_max))
        threshold_ranges[key] = rng

# 5. ãƒ¡ã‚¤ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ ------------------------------

if "selected_video_id" not in st.session_state:
    st.session_state["selected_video_id"] = None
if "search_results" not in st.session_state:
    st.session_state["search_results"] = []
if "next_page_token" not in st.session_state:
    st.session_state["next_page_token"] = None

# ã€ã‚·ãƒ¼ãƒ³1ã€‘å‹•ç”»æœªé¸æŠæ™‚ï¼ˆæ¤œç´¢ç”»é¢ï¼‰
if st.session_state["selected_video_id"] is None:
    st.markdown("### 1. å‹•ç”»ã‚’æ¤œç´¢")
    
    col1, col2 = st.columns([4, 1])
    with col1:
        query = st.text_input("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›", value="", label_visibility="collapsed", placeholder="ä¾‹: AI è§£èª¬")
    with col2:
        search_btn = st.button("æ¤œç´¢", use_container_width=True)
    
    if search_btn and query:
        st.session_state["search_results"] = []
        st.session_state["next_page_token"] = None
        results, token = search_videos(query, max_results=12) 
        st.session_state["search_results"] = results
        st.session_state["next_page_token"] = token

    if st.session_state["search_results"]:
        videos = st.session_state["search_results"]
        st.markdown(f"#### æ¤œç´¢çµæœ ({len(videos)}ä»¶ è¡¨ç¤ºä¸­)")
        
        # ã‚°ãƒªãƒƒãƒ‰è¡¨ç¤º (3åˆ—)
        N_COLS = 3
        for i in range(0, len(videos), N_COLS):
            cols = st.columns(N_COLS)
            for j in range(N_COLS):
                if i + j < len(videos):
                    v = videos[i + j]
                    with cols[j]:
                        if v["thumbnail"]:
                            st.image(v["thumbnail"], use_container_width=True)
                        title_disp = v["title"]
                        if len(title_disp) > 30: title_disp = title_disp[:30] + "..."
                        st.caption(title_disp)
                        
                        if st.button("é¸æŠ", key=f"select_{v['video_id']}"):
                            st.session_state["selected_video_id"] = v["video_id"]
                            st.session_state["selected_title"] = v["title"]
                            st.rerun()

        # ã€æ”¹å–„ç‚¹ã€‘ã‚‚ã£ã¨è¦‹ã‚‹ãƒœã‚¿ãƒ³ã®è¡¨ç¤º
        if st.session_state["next_page_token"]:
            st.divider()
            if st.button("â¬‡ï¸ ã‚‚ã£ã¨å‹•ç”»ã‚’èª­ã¿è¾¼ã‚€"):
                new_results, new_token = search_videos(
                    query, max_results=12, page_token=st.session_state["next_page_token"]
                )
                if new_results:
                    st.session_state["search_results"].extend(new_results)
                    st.session_state["next_page_token"] = new_token
                    st.rerun()

# ã€ã‚·ãƒ¼ãƒ³2ã€‘å‹•ç”»é¸æŠå¾Œï¼ˆåˆ†æç”»é¢ï¼‰
else:
    vid = st.session_state["selected_video_id"]
    st.button("ğŸ”™ æ¤œç´¢ã«æˆ»ã‚‹", on_click=lambda: st.session_state.update({"selected_video_id": None}))
    st.markdown(f"### ğŸï¸ é¸æŠä¸­: {st.session_state.get('selected_title','(no title)')}")
    st.video(f"https://www.youtube.com/watch?v={vid}")

    if st.button("ğŸ’¬ ã‚³ãƒ¡ãƒ³ãƒˆåˆ†æã‚’å®Ÿè¡Œï¼ˆä¸Šé™100ä»¶ï¼‰"):
        with st.spinner("ã‚³ãƒ¡ãƒ³ãƒˆã‚’å–å¾—ã—ã¦GPTã§åˆ†æã—ã¦ã„ã¾ã™...ï¼ˆæ•°åç§’ã€œæ•°åˆ†ï¼‰"):
            comments = get_comments(vid, max_comments=100)
            if not comments:
                st.error("ã‚³ãƒ¡ãƒ³ãƒˆã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸï¼ˆã‚³ãƒ¡ãƒ³ãƒˆç„¡åŠ¹ã¾ãŸã¯APIåˆ¶é™ã®å¯èƒ½æ€§ï¼‰")
            else:
                rows = []
                progress_bar = st.progress(0)
                
                # ä¸¦åˆ—å‡¦ç†ï¼ˆã“ã“ã‚‚æ—§ã‚³ãƒ¼ãƒ‰ã¨åŒã˜è¨­å®šï¼šWorker 10, ã‚¨ãƒ©ãƒ¼ã¯ã‚¹ã‚­ãƒƒãƒ—ï¼‰
                with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
                    future_to_comment = {executor.submit(analyze_comment, c): c for c in comments}
                    
                    for i, future in enumerate(concurrent.futures.as_completed(future_to_comment)):
                        c = future_to_comment[future]
                        try:
                            analysis = future.result()
                            row = normalize_analysis_to_row(analysis)
                            row["ã‚³ãƒ¡ãƒ³ãƒˆ"] = c
                            rows.append(row)
                        except Exception as e:
                            pass 
                        
                        progress_bar.progress((i + 1) / len(comments))

                df = pd.DataFrame(rows)
                st.session_state["analysis_df_raw"] = df
                st.success(f"{len(df)} ä»¶ã®ã‚³ãƒ¡ãƒ³ãƒˆã‚’åˆ†æã—ã¾ã—ãŸã€‚")

# 6. çµæœè¡¨ç¤º ---------------------------------
if "analysis_df_raw" in st.session_state and st.session_state["analysis_df_raw"] is not None:
    df_raw = st.session_state["analysis_df_raw"]
    df = df_raw.copy()

    mask = pd.Series([True] * len(df))
    for f in FEATURES:
        key = f["key"]
        score_col = f"{key}_score"
        low, high = threshold_ranges.get(key, (f["min"], f["max"]))
        if score_col in df.columns:
            s = pd.to_numeric(df[score_col], errors="coerce")
            mask &= s.notna() & (s >= float(low)) & (s <= float(high))
        else:
            mask &= True
    df_filtered = df[mask]

    st.markdown(f"**è¡¨ç¤ºä»¶æ•°:** {len(df_filtered)} / {len(df)} ä»¶ï¼ˆé–¾å€¤ãƒ¬ãƒ³ã‚¸ã§çµã‚Šè¾¼ã¿ï¼‰")

    display_cols = ["ã‚³ãƒ¡ãƒ³ãƒˆ"] + [f"{f['key']}_score" for f in FEATURES] + ["ç·åˆã‚³ãƒ¡ãƒ³ãƒˆ"]
    display_cols = [c for c in display_cols if c in df_filtered.columns]
    
    # ã€æ”¹å–„ç‚¹ã€‘ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’1ã‹ã‚‰é–‹å§‹
    if len(df_filtered) > 0:
        df_display = df_filtered[display_cols].reset_index(drop=True)
        df_display.index = df_display.index + 1
        st.dataframe(df_display, use_container_width=True)

        st.download_button(
            "ğŸ’¾ ãƒ•ã‚£ãƒ«ã‚¿çµæœã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            df_filtered.to_csv(index=False).encode("utf-8"),
            file_name="filtered_comment_analysis.csv",
            mime="text/csv"
        )
    else:
        st.warning("æ¡ä»¶ã«åˆã†ã‚³ãƒ¡ãƒ³ãƒˆãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

